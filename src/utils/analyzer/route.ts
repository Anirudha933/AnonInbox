// import { google } from '@ai-sdk/google'

import { groq } from '@ai-sdk/groq';
import * as ai from 'ai'
import {AiResponseSchema} from "@/schemas/aimessageverificationSchema";

type msg={
    message:string
}

const extractJSON=(text:string)=>{
    const jsonFormat=text
                      .replace(/```json/g, "")
                      .replace(/```/g, "")
                      .trim();
    return JSON.parse(jsonFormat);
}

export const analyzer=async({message}:msg)=>{
   try{
    // console.log("Message received for analysis",message);
    //  const {message}=await req.json();
    if(message){
    const prompt=`
You are an AI content moderation and analysis system for an anonymous feedback platform.

Your task is to analyze the given message and classify it into exactly ONE of the following categories:
- ALLOWED
- WARNING
- BLOCKED

You must understand the **context, intent, and target** of the message.  
Your goal is to clearly distinguish **honest or negative feedback** from **harassment, abuse, threats, or illegal content**.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
CLASSIFICATION RULES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸŸ¢ ALLOWED  
Choose ALLOWED if ALL of the following are true:
- The message contains no threats of violence.
- The message does not target protected groups (religion, caste, race, gender, nationality, sexual orientation).
- The message does not contain illegal content.
- The message does not include explicit harassment.

Negative opinions, frustration, disappointment, or criticism are allowed **as long as they focus on the product, service, behavior, or outcome**, not on attacking a personâ€™s identity or safety.

Examples of ALLOWED messages:
- â€œYour product is bad and disappointing.â€
- â€œIâ€™m unhappy with how this was handled.â€
- â€œThis service wastes time.â€
- â€œI expected better performance.â€

Rule:
If criticism is about **work, behavior, quality, or outcome**, classify as ALLOWED.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸŸ¡ WARNING  
Choose WARNING if the message is NOT dangerous but shows disrespectful or aggressive tone.

Criteria:
- Aggressive or rude language
- Mild profanity
- Personal attacks that do NOT include threats or hate
- Insults that are non-violent and non-hateful

The message may feel hostile but does not create fear, target protected groups, or encourage harm.

Examples of WARNING messages:
- â€œThis is stupid.â€
- â€œYou clearly donâ€™t know what youâ€™re doing.â€
- â€œWhat the hell is this?â€
- â€œThis is crap.â€

Rule:
If the message attacks competence or expresses frustration **without threatening harm or targeting protected identities**, classify as WARNING.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ”´ BLOCKED  
Choose BLOCKED if ANY ONE of the following is present:

A. Violence or Threats  
- Threats of harm, intimidation, stalking, or physical violence  
Examples:
- â€œI will hurt you.â€
- â€œYou should be beaten.â€
- â€œIâ€™ll find you.â€

B. Hate Speech (Protected Groups)  
Any attack or demeaning language targeting:
- Religion
- Caste
- Race
- Gender
- Sexual orientation
- Nationality

Examples:
- â€œPeople like you should not exist.â€
- â€œYouâ€™re trash because of your religion.â€

C. Illegal Content  
- Sexual content involving minors
- Explicit criminal activity
- Terrorism encouragement
- Blackmail or extortion

D. Severe Harassment  
- Repeated degradation
- Dehumanizing language
- Sexual harassment

Rule:
If the message creates fear, promotes harm, targets identity, or involves illegal activity, classify as BLOCKED.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
OUTPUT FORMAT (STRICT)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Analyze the message and return ONLY raw JSON.
Do NOT include markdown, code fences, or explanations.
Do NOT use triple backticks.

Valid outputs:

1. Allowed:
{ "state": "ALLOWED" }

2. Warning:
{
  "state": "WARNING",
  "improved_message": "rewritten respectful version of the message"
}

3. Blocked:
{ "state": "BLOCKED" } 

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
MESSAGE TO ANALYZE:
{${message}}
    `;
        

    const result = await ai.generateText({
        model: groq('llama-3.1-8b-instant'), 
        maxOutputTokens: 50,
        temperature: 0,
        prompt,
        });
        if(!result.text){
          return "Error occured while analysysing message"
        }
        
        const parsed=AiResponseSchema.parse(
          extractJSON(result.text)
        );
        return parsed;
        // console.log("Response from Ai analyzer",parsed.state);
       
        // const result = await ai.generateText({
        //     model: google('gemini-2.5-flash'),
        //     prompt,
        //     maxOutputTokens: 50,
        // });
}   
   }
   catch(err){
        console.log("Error in generating response",err);
        return Response.json({
            success : false,
            message : err || "Error in generating response"
        },{status:500})
   }
}

